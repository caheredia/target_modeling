{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Load-raw-data\" data-toc-modified-id=\"Load-raw-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load raw data</a></span></li><li><span><a href=\"#Clean-raw-data\" data-toc-modified-id=\"Clean-raw-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Clean raw data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Find-and-drop-dulicate-columns\" data-toc-modified-id=\"Find-and-drop-dulicate-columns-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Find and drop dulicate columns</a></span></li><li><span><a href=\"#Drop-columns-that-have->-80%-missing-values\" data-toc-modified-id=\"Drop-columns-that-have->-80%-missing-values-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Drop columns that have &gt; 80% missing values</a></span></li><li><span><a href=\"#Drop-columns-with-low-variance,-data-type-int64-or-float64\" data-toc-modified-id=\"Drop-columns-with-low-variance,-data-type-int64-or-float64-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Drop columns with low variance, data type int64 or float64</a></span></li><li><span><a href=\"#Drop-Categorical-values-with-low-variance-by-converting-to-labels-to-dummy-variables-and-filtering-by-threshold-variance\" data-toc-modified-id=\"Drop-Categorical-values-with-low-variance-by-converting-to-labels-to-dummy-variables-and-filtering-by-threshold-variance-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Drop Categorical values with low variance by converting to labels to dummy variables and filtering by threshold variance</a></span></li><li><span><a href=\"#Replace-NaN-values-in-numerical-columns-with-median-value-of-series\" data-toc-modified-id=\"Replace-NaN-values-in-numerical-columns-with-median-value-of-series-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Replace NaN values in numerical columns with median value of series</a></span></li><li><span><a href=\"#Find-date-like-columns-and-convert-to-timestamps,-then-to-integer-type\" data-toc-modified-id=\"Find-date-like-columns-and-convert-to-timestamps,-then-to-integer-type-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Find date like columns and convert to timestamps, then to integer type</a></span></li><li><span><a href=\"#Save-cleaned-up-dataframe-as-csv\" data-toc-modified-id=\"Save-cleaned-up-dataframe-as-csv-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>Save cleaned up dataframe as csv</a></span></li></ul></li><li><span><a href=\"#Load-cleaned-data\" data-toc-modified-id=\"Load-cleaned-data-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Load cleaned data</a></span></li><li><span><a href=\"#Preprocess-data\" data-toc-modified-id=\"Preprocess-data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Preprocess data</a></span></li><li><span><a href=\"#Models\" data-toc-modified-id=\"Models-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Logistic Regression</a></span></li><li><span><a href=\"#Support-Vector-Machine\" data-toc-modified-id=\"Support-Vector-Machine-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Support Vector Machine</a></span></li><li><span><a href=\"#Stochastic-Gradient-Descent-(SGD)\" data-toc-modified-id=\"Stochastic-Gradient-Descent-(SGD)-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Stochastic Gradient Descent (SGD)</a></span></li><li><span><a href=\"#Regression-Forest\" data-toc-modified-id=\"Regression-Forest-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>Regression Forest</a></span><ul class=\"toc-item\"><li><span><a href=\"#Decision-Tree\" data-toc-modified-id=\"Decision-Tree-6.4.1\"><span class=\"toc-item-num\">6.4.1&nbsp;&nbsp;</span>Decision Tree</a></span></li><li><span><a href=\"#Random-Forest\" data-toc-modified-id=\"Random-Forest-6.4.2\"><span class=\"toc-item-num\">6.4.2&nbsp;&nbsp;</span>Random Forest</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "https://scikit-learn.org/stable/tutorial/machine_learning_map/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src import find_duplicates, find_empty_columns, find_low_variance, find_low_var_categories, replace_NaN, time_like, convert_to_timestamp\n",
    "from src import run_models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/raw/targeting_model_data.csv' \n",
    "data = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of columns: {}'.format(data.shape[1]))\n",
    "print('Number of rows: {}'.format(data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick look at data \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Composition of target data, this demonstrates imbalanced data. And thus accuracy alone is not a good metric for assessing performance of model. \n",
    "data['FLOZVPMFT4626A'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and drop dulicate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "duplicates = find_duplicates(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of duplicate columns dropped: {}'.format(len(duplicates)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data frame excluding dropped columns \n",
    "df = data.drop(columns=duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop columns that have > 80% missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_columns = find_empty_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of mostly empty columns dropped: {}'.format(len(empty_columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frame excluding dropped columns \n",
    "df = df.drop(columns=empty_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop columns with low variance, data type int64 or float64 \n",
    "motivated by the Variance Threshold function https://scikit-learn.org/stable/modules/feature_selection.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data frame excluding dropped columns \n",
    "low_var_columns = find_low_variance(df)\n",
    "df.drop(columns=low_var_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of low variance columns dropped: {}'.format(len(low_var_columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Categorical values with low variance by converting to labels to dummy variables and filtering by threshold variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_v_categories = find_low_var_categories(df)\n",
    "df.drop(columns=low_v_categories, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of low variance category columns dropped: {}'.format(len(low_v_categories)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace NaN values in numerical columns with median value of series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df= replace_NaN(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find date like columns and convert to timestamps, then to integer type\n",
    "\n",
    "Visually inspecting time like columns we can easily find columns that are probably not meant to be timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_columns = time_like(df)\n",
    "df[time_columns].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visually inspecting items that are not potential time stamps\n",
    "not_time_columns = ['ibe8588DPLHE7435F', 'ibe8840PMLTL7040B']\n",
    "real_time_columns = [item for item in time_columns if item not in not_time_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove extra zeros from column \n",
    "df['ibe9152JHMZI9585O'] = df['ibe9152JHMZI9585O']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convert_to_timestamp(df, real_time_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[ real_time_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save cleaned up dataframe as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'data/interim/cleaned_columns.csv'\n",
    "df.to_csv(path_or_buf=filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load cleaned data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLOZVPMFT4626A</th>\n",
       "      <th>ibe1270YRFHJ3350O</th>\n",
       "      <th>ibe1271DCBOP1538T</th>\n",
       "      <th>ibe1273MMNAC5195E</th>\n",
       "      <th>ibe1274DFDFF5102Q</th>\n",
       "      <th>ibe1275QYWDP9371S</th>\n",
       "      <th>ibe1280ORQKP6566Z</th>\n",
       "      <th>ibe1281AGNWU9303H</th>\n",
       "      <th>ibe1281VSZLA4159S</th>\n",
       "      <th>ibe2062AHFGH0763Q</th>\n",
       "      <th>...</th>\n",
       "      <th>ibe9153QSXNN0648A</th>\n",
       "      <th>ibe9154GOSYR7154P</th>\n",
       "      <th>ibe9180FFUYI1365V</th>\n",
       "      <th>ibe9181PWJGU8847L</th>\n",
       "      <th>ibe9350NHRIV6568X</th>\n",
       "      <th>ibe9351VNIYI1676Y</th>\n",
       "      <th>ibe9356VXVDJ5952B</th>\n",
       "      <th>ibe9358UBJWE4744M</th>\n",
       "      <th>ibe9509UGCNU4337M</th>\n",
       "      <th>ibe9514RWCHD8503K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12B</td>\n",
       "      <td>9.0</td>\n",
       "      <td>01C</td>\n",
       "      <td>01C</td>\n",
       "      <td>35.0</td>\n",
       "      <td>09L</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>C1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11B</td>\n",
       "      <td>7.0</td>\n",
       "      <td>01C</td>\n",
       "      <td>01C</td>\n",
       "      <td>11.0</td>\n",
       "      <td>04M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>A1</td>\n",
       "      <td>L1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>B</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>06X</td>\n",
       "      <td>12.0</td>\n",
       "      <td>03C</td>\n",
       "      <td>11C</td>\n",
       "      <td>38.0</td>\n",
       "      <td>12L</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12B</td>\n",
       "      <td>5.0</td>\n",
       "      <td>05C</td>\n",
       "      <td>07U</td>\n",
       "      <td>14.0</td>\n",
       "      <td>05M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>05X</td>\n",
       "      <td>7.0</td>\n",
       "      <td>05C</td>\n",
       "      <td>08C</td>\n",
       "      <td>33.0</td>\n",
       "      <td>11L</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>B6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FLOZVPMFT4626A  ibe1270YRFHJ3350O ibe1271DCBOP1538T  ibe1273MMNAC5195E  \\\n",
       "0               0               17.0               12B                9.0   \n",
       "1               0                1.0               11B                7.0   \n",
       "2               0               61.0               06X               12.0   \n",
       "3               0               13.0               12B                5.0   \n",
       "4               0               37.0               05X                7.0   \n",
       "\n",
       "  ibe1274DFDFF5102Q ibe1275QYWDP9371S  ibe1280ORQKP6566Z ibe1281AGNWU9303H  \\\n",
       "0               01C               01C               35.0               09L   \n",
       "1               01C               01C               11.0               04M   \n",
       "2               03C               11C               38.0               12L   \n",
       "3               05C               07U               14.0               05M   \n",
       "4               05C               08C               33.0               11L   \n",
       "\n",
       "  ibe1281VSZLA4159S  ibe2062AHFGH0763Q        ...          ibe9153QSXNN0648A  \\\n",
       "0                 3                  1        ...                          1   \n",
       "1                 1                  0        ...                          0   \n",
       "2                 3                  0        ...                          0   \n",
       "3                 1                  0        ...                          0   \n",
       "4                 1                  0        ...                          0   \n",
       "\n",
       "   ibe9154GOSYR7154P  ibe9180FFUYI1365V ibe9181PWJGU8847L  ibe9350NHRIV6568X  \\\n",
       "0                 C1                NaN               NaN               13.0   \n",
       "1                 A1                 L1               NaN                4.0   \n",
       "2                NaN                NaN               NaN               25.0   \n",
       "3                NaN                 M1               NaN               14.0   \n",
       "4                 B6                NaN               NaN               13.0   \n",
       "\n",
       "   ibe9351VNIYI1676Y  ibe9356VXVDJ5952B  ibe9358UBJWE4744M  ibe9509UGCNU4337M  \\\n",
       "0               13.0                  5                9.0                1.0   \n",
       "1               13.0                  B                2.0                1.0   \n",
       "2                5.0                  1               15.0                1.0   \n",
       "3                5.0                  7                7.0                1.0   \n",
       "4               10.0                  6               10.0                1.0   \n",
       "\n",
       "   ibe9514RWCHD8503K  \n",
       "0                1.0  \n",
       "1                2.0  \n",
       "2                1.0  \n",
       "3                2.0  \n",
       "4                2.0  \n",
       "\n",
       "[5 rows x 187 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'data/interim/cleaned_columns.csv'\n",
    "df = pd.read_csv(filename)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data \n",
    "X =pd.get_dummies(df.iloc[:,1:20]).values\n",
    "target = df.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 319) (25000, 319)\n"
     ]
    }
   ],
   "source": [
    "# split the data\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, target, random_state=2)\n",
    "print(Xtrain.shape, Xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(Xtrain)  # fit only on training data\n",
    "Xtrain = scaler.transform(Xtrain)\n",
    "Xtest = scaler.transform(Xtest)  # apply same transformation to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of random array: 0.0\n",
      "Std of random array: 1.0\n"
     ]
    }
   ],
   "source": [
    "# verify preprocess is working correctly \n",
    "print('Mean of random array: {}'.format(round(Xtrain[:,8].mean())))\n",
    "print('Std of random array: {}'.format(round(Xtrain[:,8].std())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# label data\n",
    "target_names = ['0', '1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "cl2 = LogisticRegression( class_weight='balanced', fit_intercept=False, solver='liblinear')\n",
    "\n",
    "t0 = time()\n",
    "clf.fit(Xtrain, ytrain)\n",
    "train_time = time() - t0\n",
    "print(\"train time: {:0.2f}s\".format( train_time))\n",
    "\n",
    "t0 = time()\n",
    "ypred = clf.predict(Xtest)\n",
    "test_time = time() - t0\n",
    "print('test time: {:0.2f}s \\n'.format( test_time))\n",
    "accuracy_score(ytest, ypred)\n",
    "print(classification_report(ytest, ypred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent (SGD)\n",
    "https://scikit-learn.org/stable/tutorial/machine_learning_map/\n",
    "\n",
    "https://scikit-learn.org/stable/modules/sgd.html#classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss=\"hinge\", max_iter=20, class_weight='balanced',  fit_intercept=False)\n",
    "\n",
    "t0 = time()\n",
    "clf.fit(Xtrain, ytrain)\n",
    "train_time = time() - t0\n",
    "print(\"train time: {:0.2f}s\".format( train_time))\n",
    "\n",
    "t0 = time()\n",
    "ypred = clf.predict(Xtest)\n",
    "test_time = time() - t0\n",
    "print('test time: {:0.2f}s \\n'.format( test_time))\n",
    "accuracy_score(ytest, ypred)\n",
    "print(classification_report(ytest, ypred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=11, class_weight='balanced')\n",
    "\n",
    "t0 = time()\n",
    "clf.fit(Xtrain, ytrain)\n",
    "train_time = time() - t0\n",
    "print(\"train time: {:0.2f}s\".format( train_time))\n",
    "\n",
    "t0 = time()\n",
    "ypred = clf.predict(Xtest)\n",
    "test_time = time() - t0\n",
    "print('test time: {:0.2f}s \\n'.format( test_time))\n",
    "accuracy_score(ytest, ypred)\n",
    "print(classification_report(ytest, ypred,target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier( n_estimators=100, n_jobs=-1, class_weight='balanced')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate dict with classifiers \n",
    "model_dict = {}\n",
    "\n",
    "Logistic_Regression = LogisticRegression( class_weight='balanced', fit_intercept=False, solver='liblinear')\n",
    "model_dict['Logistic Regression']  = Logistic_Regression\n",
    "\n",
    "SGD = SGDClassifier(loss=\"hinge\", max_iter=20, class_weight='balanced',  fit_intercept=False)\n",
    "model_dict['Stochastic Gradient Descent']  = SGD\n",
    "\n",
    "DT = DecisionTreeClassifier(max_depth=11, class_weight='balanced')\n",
    "model_dict['Decision Tree']  = DT\n",
    "\n",
    "RT =  RandomForestClassifier( n_estimators=100, n_jobs=-1, class_weight='balanced')\n",
    "model_dict['Random Forest']  = RT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(Xtrain, ytrain, Xtest, ytest, model_dict): \n",
    "    \"\"\"Runs a list of models.\n",
    "\n",
    "    Runs a list of models defined in model_dict.\n",
    "    Tax\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Xtrain : numpy.ndarray \n",
    "        training data \n",
    "    ytrain : numpy.ndarray \n",
    "        training target data \n",
    "    Xtest : numpy.ndarray \n",
    "        test data \n",
    "    ytrain : numpy.ndarray \n",
    "        training test data \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    for name in model_dict:\n",
    "        print(name)\n",
    "\n",
    "        clf = model_dict[name]\n",
    "        t0 = time()\n",
    "        clf.fit(Xtrain, ytrain)\n",
    "        train_time = time() - t0\n",
    "        print(\"train time: {:0.2f}s\".format( train_time))\n",
    "\n",
    "        t0 = time()\n",
    "        ypred = clf.predict(Xtest)\n",
    "        test_time = time() - t0\n",
    "        print('test time: {:0.2f}s \\n'.format( test_time))\n",
    "        accuracy_score(ytest, ypred)\n",
    "        print(classification_report(ytest, ypred,target_names=target_names))\n",
    "        print('-' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "train time: 64.09s\n",
      "test time: 0.03s \n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a626d2f6117d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Volumes/Samy/Projects/target_modeling/src/models/predict_train_model.py\u001b[0m in \u001b[0;36mrun_models\u001b[0;34m(Xtrain, ytrain, Xtest, ytest, model_dict)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mtest_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test time: {:0.2f}s \\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mypred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mypred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "run_models(Xtrain, ytrain, Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
